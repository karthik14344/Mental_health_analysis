{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "import logging\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt', quiet=True)\n",
    "from src.reddit_mental_health_extractor import RedditMentalHealthDataExtractor\n",
    "\n",
    "class EnhancedMentalHealthRiskClassifier:\n",
    "    def __init__(self):\n",
    "        # High-risk keywords for initial reference\n",
    "        self.high_risk_terms = [\n",
    "            \"suicide\", \"kill myself\", \"want to die\", \"end it all\",\n",
    "            \"no hope\", \"can't go on\", \"death\", \"suicidal thoughts\",\n",
    "            \"self-harm\", \"cutting\", \"overdose\", \"i want to die\"\n",
    "        ]\n",
    "\n",
    "        # Moderate concern keywords for initial reference\n",
    "        self.moderate_risk_terms = [\n",
    "            \"struggling\", \"help\", \"can\\'t cope\", \"overwhelmed\", \n",
    "            \"depression\", \"anxiety\", \"mental breakdown\", \n",
    "            \"feeling lost\", \"ptsd\", \"burnout\", \"addiction\", \n",
    "            \"substance abuse\", \"emotional pain\"\n",
    "        ]\n",
    "        \n",
    "        # Initialize TF-IDF Vectorizer\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        \n",
    "        # Load pre-trained Word2Vec model\n",
    "        try:\n",
    "            logging.getLogger('gensim').setLevel(logging.CRITICAL)\n",
    "            self.word2vec_model = api.load('word2vec-google-news-300')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Word2Vec model: {e}\")\n",
    "            self.word2vec_model = None\n",
    "\n",
    "    def classify_sentiment(self, text):\n",
    "        \"\"\"\n",
    "        Classify sentiment using TextBlob with enhanced granularity\n",
    "        \"\"\"\n",
    "        blob = TextBlob(str(text))\n",
    "        polarity = blob.sentiment.polarity\n",
    "        \n",
    "        if polarity > 0.3:\n",
    "            return 'Very Positive'\n",
    "        elif polarity > 0.1:\n",
    "            return 'Positive'\n",
    "        elif polarity < -0.3:\n",
    "            return 'Very Negative'\n",
    "        elif polarity < -0.1:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "\n",
    "    def tfidf_risk_detection(self, text, risk_terms):\n",
    "        \"\"\"\n",
    "        Use TF-IDF to detect risk-related terms\n",
    "        \"\"\"\n",
    "        # Combine text with risk terms\n",
    "        corpus = [text] + risk_terms\n",
    "        \n",
    "        # Compute TF-IDF\n",
    "        tfidf_matrix = self.tfidf_vectorizer.fit_transform(corpus)\n",
    "        \n",
    "        # Compute cosine similarity between text and risk terms\n",
    "        similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
    "        \n",
    "        # If any similarity is high, consider it a match\n",
    "        return max(similarities) > 0.3\n",
    "\n",
    "    def word2vec_risk_detection(self, text, risk_terms):\n",
    "        \"\"\"\n",
    "        Use Word2Vec for semantic similarity detection\n",
    "        \"\"\"\n",
    "        if self.word2vec_model is None:\n",
    "            return False\n",
    "        \n",
    "        # Tokenize text\n",
    "        text_words = text.lower().split()\n",
    "        \n",
    "        # Compute average vector for text\n",
    "        try:\n",
    "            text_vector = np.mean([self.word2vec_model[word] for word in text_words \n",
    "                                   if word in self.word2vec_model], axis=0)\n",
    "        except:\n",
    "            return False\n",
    "        \n",
    "        # Check semantic similarity with risk terms\n",
    "        for term in risk_terms:\n",
    "            term_words = term.lower().split()\n",
    "            try:\n",
    "                term_vector = np.mean([self.word2vec_model[word] for word in term_words \n",
    "                                       if word in self.word2vec_model], axis=0)\n",
    "                \n",
    "                # Compute cosine similarity\n",
    "                similarity = np.dot(text_vector, term_vector) / (\n",
    "                    np.linalg.norm(text_vector) * np.linalg.norm(term_vector)\n",
    "                )\n",
    "                \n",
    "                if similarity > 0.7:  # High semantic similarity threshold\n",
    "                    return True\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def classify_risk_level(self, text):\n",
    "        \"\"\"\n",
    "        Enhanced risk classification using multiple techniques\n",
    "        \"\"\"\n",
    "        text_lower = str(text).lower()\n",
    "        \n",
    "        # Check for exact keyword matches\n",
    "        for term in self.high_risk_terms:\n",
    "            if term in text_lower:\n",
    "                return 'High Risk'\n",
    "        \n",
    "        # TF-IDF Risk Detection\n",
    "        if self.tfidf_risk_detection(text, self.high_risk_terms):\n",
    "            return 'High Risk'\n",
    "        \n",
    "        # Word2Vec Semantic Similarity\n",
    "        if self.word2vec_risk_detection(text, self.high_risk_terms):\n",
    "            return 'High Risk'\n",
    "        \n",
    "        # Similar process for moderate risk\n",
    "        for term in self.moderate_risk_terms:\n",
    "            if term in text_lower:\n",
    "                return 'Moderate Concern'\n",
    "        \n",
    "        if self.tfidf_risk_detection(text, self.moderate_risk_terms):\n",
    "            return 'Moderate Concern'\n",
    "        \n",
    "        if self.word2vec_risk_detection(text, self.moderate_risk_terms):\n",
    "            return 'Moderate Concern'\n",
    "        \n",
    "        return 'Low Concern'\n",
    "\n",
    "    def process_posts(self, posts_dataframe):\n",
    "        \"\"\"\n",
    "        Process posts and add sentiment and risk level columns\n",
    "        \"\"\"\n",
    "        # Add sentiment column\n",
    "        posts_dataframe['Sentiment'] = posts_dataframe['content'].apply(self.classify_sentiment)\n",
    "        \n",
    "        # Add risk level column\n",
    "        posts_dataframe['Risk Level'] = posts_dataframe['content'].apply(self.classify_risk_level)\n",
    "        \n",
    "        return posts_dataframe\n",
    "\n",
    "    def generate_risk_distribution(self, processed_df):\n",
    "        \"\"\"\n",
    "        Generate distribution of posts by sentiment and risk level\n",
    "        \"\"\"\n",
    "        # Create cross-tabulation\n",
    "        risk_distribution = pd.crosstab(\n",
    "            processed_df['Sentiment'], \n",
    "            processed_df['Risk Level']\n",
    "        )\n",
    "        \n",
    "        return risk_distribution\n",
    "\n",
    "    def save_results(self, processed_df, distribution, base_filename='mental_health_analysis'):\n",
    "        \"\"\"\n",
    "        Save processed results to CSV and generate visualization\n",
    "        \"\"\"\n",
    "        # Create output directory\n",
    "        os.makedirs('output', exist_ok=True)\n",
    "        \n",
    "        # Save processed dataframe\n",
    "        processed_filename = os.path.join('output', f'{base_filename}_processed.csv')\n",
    "        processed_df.to_csv(processed_filename, index=False)\n",
    "        print(f\"Processed data saved to {processed_filename}\")\n",
    "        \n",
    "        # Save distribution\n",
    "        dist_filename = os.path.join('output', f'{base_filename}_distribution.csv')\n",
    "        distribution.to_csv(dist_filename)\n",
    "        print(f\"Risk distribution saved to {dist_filename}\")\n",
    "        \n",
    "        # Create heatmap visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(distribution, annot=True, cmap='YlGnBu', fmt='g')\n",
    "        plt.title('Mental Health Posts: Sentiment vs Risk Level')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save heatmap\n",
    "        heatmap_filename = os.path.join('output', f'{base_filename}_heatmap.png')\n",
    "        plt.savefig(heatmap_filename)\n",
    "        print(f\"Heatmap visualization saved to {heatmap_filename}\")\n",
    "        \n",
    "        return distribution\n",
    "      \n",
    "      \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
